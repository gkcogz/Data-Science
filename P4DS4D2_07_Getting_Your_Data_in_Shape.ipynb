{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out whatâ€™s in your data & Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "\n",
      "  Number  String Boolean\n",
      "0      1   First    True\n",
      "1      2  Second   False\n",
      "2      3   Third    True\n",
      "\n",
      "Duplicate Rows:\n",
      "\n",
      "  Number String Boolean\n",
      "3      3  Third    True\n"
     ]
    }
   ],
   "source": [
    "#First, the libraries are imported.\n",
    "from lxml import objectify\n",
    "import pandas as pd\n",
    "\n",
    "#parse means 'ayristirma'\n",
    "xml = objectify.parse(open('XMLData2.xml'))\n",
    "\n",
    "#You obtain access to the root node using the getroot() method. Because XML are structured over a root node, analog to a tree.\n",
    "root = xml.getroot()\n",
    "\n",
    "#Data handling relies on a DataFrame.\n",
    "df = pd.DataFrame(columns=('Number', 'String', 'Boolean'))\n",
    "\n",
    "for i in range(0, 4):\n",
    "    obj = root.getchildren()[i].getchildren()\n",
    "    \n",
    "    df.loc[i, 'Number'] = obj[0].text\n",
    "    df.loc[i, 'String'] = obj[1].text\n",
    "    df.loc[i, 'Boolean'] = obj[2].text\n",
    "    # Print extracted values for debugging\n",
    "    #print([obj[0].text, obj[1].text, obj[2].text])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print()\n",
    "print(df.drop_duplicates())\n",
    "print()\n",
    "    \n",
    "#Check for duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"Duplicate Rows:\")\n",
    "print()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data map and data plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      B                                            \\\n",
      "  count      mean       std  min   25%  50%   75%   \n",
      "A                                                   \n",
      "0   5.0  3.000000  1.581139  1.0  2.00  3.0  4.00   \n",
      "1   6.0  4.833333  1.722401  2.0  4.25  5.0  5.75   \n",
      "\n",
      "           C                                          \n",
      "   max count mean       std  min  25%  50%  75%  max  \n",
      "A                                                     \n",
      "0  5.0   5.0  2.8  1.788854  1.0  1.0  3.0  4.0  5.0  \n",
      "1  7.0   6.0  2.5  1.048809  1.0  2.0  2.5  3.0  4.0  \n"
     ]
    }
   ],
   "source": [
    "#Modified\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 55)\n",
    "\n",
    "df = pd.DataFrame({'A': [0,0,0,0,0,1,1,1,1,1,1],\n",
    "                   'B': [1,2,3,5,4,2,5,6,7,5,4],\n",
    "                   'C': [5,3,4,1,1,2,3,4,3,2,1]})\n",
    "\n",
    "a_group_desc = df.groupby('A').describe()\n",
    "print(a_group_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B         C\n",
      "A                          \n",
      "0 count  5.000000  5.000000\n",
      "  mean   3.000000  2.800000\n",
      "  std    1.581139  1.788854\n",
      "  min    1.000000  1.000000\n",
      "  25%    2.000000  1.000000\n",
      "  50%    3.000000  3.000000\n",
      "  75%    4.000000  4.000000\n",
      "  max    5.000000  5.000000\n",
      "1 count  6.000000  6.000000\n",
      "  mean   4.833333  2.500000\n",
      "  std    1.722401  1.048809\n",
      "  min    2.000000  1.000000\n",
      "  25%    4.250000  2.000000\n",
      "  50%    5.000000  2.500000\n",
      "  75%    5.750000  3.000000\n",
      "  max    7.000000  4.000000\n"
     ]
    }
   ],
   "source": [
    "stacked = a_group_desc.stack()\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      B               C     \n",
      "  count      mean count mean\n",
      "A                           \n",
      "0   5.0  3.000000   5.0  2.8\n",
      "1   6.0  4.833333   6.0  2.5\n"
     ]
    }
   ],
   "source": [
    "print(a_group_desc.loc[:,(slice(None),['count','mean']),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Checking your version of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Blue\n",
      "1      Red\n",
      "2    Green\n",
      "dtype: category\n",
      "Categories (3, object): ['Blue', 'Green', 'Red']\n",
      "\n",
      "0      NaN\n",
      "1    Green\n",
      "2      Red\n",
      "3     Blue\n",
      "4      NaN\n",
      "dtype: category\n",
      "Categories (3, object): ['Blue', 'Green', 'Red']\n",
      "\n",
      "0    True\n",
      "4    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#catergorical variable is created. dytpe set to category\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "                       dtype='category')\n",
    "\n",
    "#NaN is created when there is no match.\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Yellow', 'Green', 'Red', 'Blue', 'Purple'], \n",
    "                   categories=car_colors, ordered=False))\n",
    "\n",
    "#You ask panda which entries are actually null.\n",
    "find_entries = pd.isnull(car_data)\n",
    "\n",
    "print(car_colors)\n",
    "print()\n",
    "print(car_data)\n",
    "print()\n",
    "\n",
    "#This verifies the fact for you.\n",
    "print(find_entries[find_entries == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Purple\n",
      "1    Yellow\n",
      "2     Mauve\n",
      "dtype: category\n",
      "Categories (3, object): ['Purple', 'Yellow', 'Mauve']\n"
     ]
    }
   ],
   "source": [
    "#The error you're encountering is due to the fact that the 'categories' \n",
    "#property of a Categorical object in pandas is not directly modifiable.\n",
    "import pandas as pd\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "                       dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "        ['Blue', 'Green', 'Red', 'Blue', 'Red'],\n",
    "        categories=car_colors, ordered=False))\n",
    "\n",
    "new_categories = [\"Purple\", \"Yellow\", \"Mauve\"]\n",
    "\n",
    "# Create a new categorical variable with the desired categories\n",
    "new_car_colors = pd.Categorical(['Purple', 'Yellow', 'Mauve'], categories=new_categories, ordered=False)\n",
    "\n",
    "# Assign the new categories to the car_data\n",
    "car_data = pd.Series(new_car_colors)\n",
    "\n",
    "print(car_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0    Blue_Red\n",
      "1       Green\n",
      "2    Blue_Red\n",
      "3       Green\n",
      "4    Blue_Red\n",
      "5       Green\n",
      "dtype: category\n",
      "Categories (2, object): ['Green', 'Blue_Red']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_colors = pd.Series(['Blue', 'Red', 'Green'],\n",
    "    dtype='category')\n",
    "car_data = pd.Series(\n",
    "    pd.Categorical(\n",
    "       ['Blue', 'Green', 'Red', 'Green', 'Red', 'Green'],\n",
    "       categories=car_colors, ordered=False))\n",
    "\n",
    "car_data = car_data.cat.set_categories(\n",
    "    [\"Blue\", \"Red\", \"Green\", \"Blue_Red\"])\n",
    "\n",
    "#Combining Blue and Red together is a two-step process. First, you add the Blue_Red to car_data.\n",
    "#Then you change Red and Blue entries to Blue_Red.\n",
    "#print(car_data.loc[car_data.isin(['Red'])])\n",
    "\n",
    "#isin() locates the Red entries, and loc[], which obtains their index. \n",
    "car_data.loc[car_data.isin(['Red'])] = 'Blue_Red'\n",
    "car_data.loc[car_data.isin(['Blue'])] = 'Blue_Red'\n",
    "\n",
    "#As a final step, you can remove the unneeded categories.\n",
    "car_data = car_data.cat.set_categories(\n",
    "    [\"Green\", \"Blue_Red\"])\n",
    "\n",
    "print()\n",
    "print(car_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Dates in Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting date and time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 15:37:21.846715\n",
      "Mon, 01 January 2024\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "now = dt.datetime.now()\n",
    "\n",
    "print(str(now))\n",
    "print(now.strftime('%a, %d %B %Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the right time transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:37:21\n",
      "17:37:21\n",
      "2:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "#You can use days, seconds, microseconds, milliseconds, minutes, hours, weeks.\n",
    "#now is the local time.\n",
    "now = dt.datetime.now()\n",
    "timevalue = now + dt.timedelta(hours=2)\n",
    "\n",
    "print(now.strftime('%H:%M:%S'))\n",
    "print(timevalue.strftime('%H:%M:%S'))\n",
    "print(timevalue - now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "3   NaN\n",
      "6   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1, 2, 3, np.NaN, 5, 6, None])\n",
    "\n",
    "print(s.isnull())\n",
    "\n",
    "print()\n",
    "print(s[s.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A    B\n",
      "0  0  1.0\n",
      "1  0  2.0\n",
      "2  0  3.0\n",
      "3  0  NaN\n",
      "4  0  5.0\n",
      "5  0  6.0\n",
      "6  0  NaN\n",
      "\n",
      "      B                                        \n",
      "  count mean       std  min  25%  50%  75%  max\n",
      "A                                              \n",
      "0   5.0  3.4  2.073644  1.0  2.0  3.0  5.0  6.0\n",
      "\n",
      "   A    B\n",
      "0  0  1.0\n",
      "1  0  2.0\n",
      "2  0  3.0\n",
      "3  0  3.4\n",
      "4  0  5.0\n",
      "5  0  6.0\n",
      "6  0  3.4\n",
      "\n",
      "   A    B\n",
      "0  0  1.0\n",
      "1  0  2.0\n",
      "2  0  3.0\n",
      "4  0  5.0\n",
      "5  0  6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.DataFrame({'A': [0,0,0,0,0,0,0],\n",
    "                  'B': [1, 2, 3, np.NaN, 5, 6, None]})\n",
    "\n",
    "#.desribe() gives you count, mean, std , min, max values etc.\n",
    "group_desc = s.groupby('A').describe()\n",
    "print(s)\n",
    "print()\n",
    "print(group_desc)\n",
    "print()\n",
    "\n",
    "#.fillna fills the gap with the mean value.\n",
    "#s.mean worked.\n",
    "print(s.fillna(s.mean()))\n",
    "print()\n",
    "\n",
    "#.dropna removes np.NaN\n",
    "print(s.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "5    6.0\n",
      "6    7.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Modified code gpt.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Create a sample dataset.\n",
    "s = [[1, 2, 3, np.NaN, 5, 6, None]]\n",
    "\n",
    "#We define what to look for. axis=0 to impute along columns. axis=1 to impute along rows. \n",
    "#stragety can be mean, median, most_frequent.\n",
    "#imp = SimpleImputer(missing_values='NaN',\n",
    "              #strategy='mean', axis=0)\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "\n",
    "#statistics for imputer. It has seven inputs == len(s)\n",
    "imp.fit([[1, 2, 3, 4, 5, 6, 7]])\n",
    "\n",
    "#.tolist converts output to a list.\n",
    "#.transform() on s to fill in the missing values.\n",
    "x = pd.Series(imp.transform(s).tolist()[0])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing and Dicing: Filtering and Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 12, 13],\n",
       "       [14, 15, 16],\n",
       "       [17, 18, 19]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#The following example builds a 3-D array. \n",
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "             [[11,12,13], [14,15,16], [17,18,19],],\n",
    "             [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "#It then slices row 1 of that array to produce the following output:\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6],\n",
       "       [14, 15, 16],\n",
       "       [24, 25, 26]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "             [[11,12,13], [14,15,16], [17,18,19],],\n",
    "             [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "#The indexing now occurs at two levels. The first index refers to row. Using the colon(:) means to use all the rows. It prints the whole column 1.\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 15 16]\n",
      "[ 5 15 25]\n",
      "[12 15 18]\n",
      "\n",
      "[[[14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9],],\n",
    "             [[11,12,13], [14,15,16], [17,18,19],],\n",
    "             [[21,22,23], [24,25,26], [27,28,29]]])\n",
    "\n",
    "#row 1, column 1.\n",
    "print(x[1,1])\n",
    "\n",
    "#whole row, column 1, z = 1.\n",
    "print(x[:,1,1])\n",
    "\n",
    "#row 1, z = 1\n",
    "print(x[1,:,1])\n",
    "print()\n",
    "\n",
    "#rows 1 and 2, columns 1 and 2.\n",
    "print(x[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating and Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new cases and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "\n",
      "   A  B  C\n",
      "0  2  1  5\n",
      "1  3  2  3\n",
      "2  1  3  4\n",
      "3  4  4  4\n",
      "4  5  5  5\n",
      "\n",
      "   A  B  C  D\n",
      "0  2  1  5  1\n",
      "1  3  2  3  2\n",
      "2  1  3  4  3\n",
      "3  4  4  4  4\n",
      "4  5  5  5  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [2,3,1],\n",
    "                   'B': [1,2,3],\n",
    "                   'C': [5,3,4]})\n",
    "\n",
    "df1 = pd.DataFrame({'A': [4],\n",
    "                    'B': [4],\n",
    "                    'C': [4]})\n",
    "\n",
    "#The easiest way to add more data is to rely on the append() method.\n",
    "#append() has been removed in panda 2.0+, use .concat instead.\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "#Use the reset_index() method to create a new index to make accessing cases earlier.\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "#Alternatively, you can create the new case directly.\n",
    "df.loc[df.last_valid_index() + 1] = [5, 5, 5]\n",
    "print()\n",
    "print(df)\n",
    "\n",
    "#Sometimes, you need add a new variable to the DataFrame. In this case, you rely on join() to perform the task.\n",
    "#\n",
    "df2 = pd.DataFrame({'D': [1, 2, 3, 4, 5]})\n",
    "\n",
    "df = pd.DataFrame.join(df, df2)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [2,3,1],\n",
    "                   'B': [1,2,3],\n",
    "                   'C': [5,3,4]})\n",
    "\n",
    "#To remove just one case.\n",
    "df = df.drop(df.index[[1]])\n",
    "print(df)\n",
    "\n",
    "#This example shows how to remove a column using a column name. In both cases, you must specify an axis as part of\n",
    "#the removal process. Note the correction by gpt: axis = 1.\n",
    "df = df.drop('B', axis=1)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A      B  C\n",
      "0  1      2  3\n",
      "1  2      3  4\n",
      "2  2  Fatih  5\n",
      "3  3      4  1\n",
      "4  3      5  1\n",
      "5  4      5  3\n",
      "6  5      2  2\n",
      "\n",
      "   A      B  C\n",
      "0  3      4  1\n",
      "1  5      2  2\n",
      "2  2      3  4\n",
      "3  4      5  3\n",
      "4  1      2  3\n",
      "5  3      5  1\n",
      "6  2  Fatih  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'A': [2,1,2,3,3,5,4],\n",
    "                   'B': ['Fatih',2,3,5,4,2,5],\n",
    "                   'C': [5,3,4,1,1,2,3]})\n",
    "\n",
    "#To sort the data, you use .sort_values, ascending/descending.\n",
    "#A or B will be sorted, the rest keeps up.\n",
    "df = df.sort_values(by=['A', 'B'], ascending=[True, True])\n",
    "\n",
    "\n",
    "#Make sure to always call reset_index() when you' re done. \n",
    "df = df.reset_index(drop=True)\n",
    "print(df)\n",
    "\n",
    "#First, acquire the current index by:\n",
    "index = df.index.tolist()\n",
    "\n",
    "#Now, create a new order for index.\n",
    "np.random.shuffle(index)\n",
    "\n",
    "#Apply the new order to df using loc[].\n",
    "df = df.loc[df.index[index]]\n",
    "\n",
    "#As always, you call reset_index() to finalize the new order.\n",
    "df = df.reset_index(drop=True)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Adi    Soyadi     TCKN\n",
      "0   Veli      Deli  2272727\n",
      "1    Ali  Vodafone  2727277\n",
      "2  Fatma     Celik  3272772\n",
      "3   Ayse      Kaya  5247727\n"
     ]
    }
   ],
   "source": [
    "#Manuel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'Adi': ['Ayse','Fatma','Ali','Veli'],\n",
    "                   'Soyadi': ['Kaya','Celik','Vodafone','Deli'],\n",
    "                   'TCKN': [5247727,3272772, 2727277, 2272727]})\n",
    "\n",
    "#To sort the data, you use .sort_values, ascending/descending.\n",
    "#A or B will be sorted, the rest keeps up.\n",
    "df = df.sort_values(by=['TCKN'], ascending=[True])\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Data at Any Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Map  Values  S    M    V\n",
      "0    0       1  6  2.0  1.0\n",
      "1    0       2  6  2.0  1.0\n",
      "2    0       3  6  2.0  1.0\n",
      "3    1       5  9  4.5  0.5\n",
      "4    1       4  9  4.5  0.5\n",
      "5    2       2  7  3.5  4.5\n",
      "6    2       5  7  3.5  4.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Modified by gpt: To address these warnings and future-proof your code, you can pass the strings \"sum\", \"mean\", and \n",
    "#\"var\" directly to the transform function.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'Map': [0,0,0,1,1,2,2],\n",
    "                   'Values': [1,2,3,5,4,2,5]})\n",
    "\n",
    "#To perform the aggregation, you must first call groupby() to map the group values.\n",
    "#You then index into Values and rely on the transform() to create the aggregated data using one of algorithms found in NumPy.\n",
    "df['S'] = df.groupby('Map')['Values'].transform('sum')\n",
    "df['M'] = df.groupby('Map')['Values'].transform('mean')\n",
    "df['V'] = df.groupby('Map')['Values'].transform('var')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
